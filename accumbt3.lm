#
# Tokens
#


# Any single character can be a literal
lex
{
	# Ignore whitespace.
	ignore /[ \t\n\r\v]+/

	# Open and close id
	token id /[a-zA-Z_][a-zA-Z0-9_]*/

	token open_paren /'('/ 
	{
		parse_stop NC: nested_comment[ input ]
		print( 'discarding: ' NC.tree '\n' )
	}
}

#
# Token translation
#

lex
{
	literal '(', ')'
	token nc_data /[^()]+/
}

def nc_item 
	[nc_data]
|	[nested_comment]

def nested_comment 
	['(' nc_item* ')']

def nested [id*]

context accum_bt
{
	NestedParser: accum<nested>

	lex
	{
		ignore /[ \t]+/
		token word /[a-zA-Z0-9/*+_\-]+/
		token stuff /[a-zA-Z0-9()/*+_\- ]+/
		literal '!', ';', '\n'

		def A1 []
			{ print( "A1\n" ) }

		def A2 []
			{ print( "A2\n" ) }

		def item
			[word]
			{
				send NestedParser [' ']
				send NestedParser [$r1]
				send NestedParser [' ']
			}
		|
			[stuff]
			{
				send NestedParser [' ']
				send NestedParser [$r1]
				send NestedParser [' ']
			}

		def two 
		[A1 item* '!' '\n']
		|
		[A2 item* ';' '\n']
	}
}

cons AccumBt: accum_bt[]
AccumBt.NestedParser = cons parser<nested>[]

parse TwoParser: accum_bt::two(AccumBt)[ stdin ]
Two: accum_bt::two = TwoParser.tree

Nested: nested = AccumBt.NestedParser.finish()

print( '\n------------\n' )
print( ^Nested '\n' )
print( ^Two '\n' )

